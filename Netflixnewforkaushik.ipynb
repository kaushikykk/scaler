{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN3meMUztk31fostvR1Ysx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushikykk/scaler/blob/main/Netflixnewforkaushik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpiTdI7m1HOf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c-pdh7Edr-y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ace_tools as tools\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv('netflix_titles.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def summarize(self):\n",
        "        \"\"\"\n",
        "        Summarizes the DataFrame by providing:\n",
        "        - Size of the DataFrame (rows, columns)\n",
        "        - Columns with no missing values\n",
        "        - Columns where all values are unique (no duplicates)\n",
        "        - Standardizes datetime columns to a common format\n",
        "        \"\"\"\n",
        "        # Get DataFrame shape\n",
        "        num_rows, num_columns = self.df.shape\n",
        "\n",
        "        # Identify columns with no null values\n",
        "        no_null_cols = [col for col in self.df.columns if self.df[col].isna().sum() == 0]\n",
        "\n",
        "        # Identify columns where all values are unique (no duplicates)\n",
        "        no_duplicates_cols = [col for col in self.df.columns if self.df[col].nunique() == num_rows]\n",
        "\n",
        "        # Convert datetime columns to a standardized format if possible\n",
        "        for col in self.df.select_dtypes(include=['object']).columns:\n",
        "            try:\n",
        "                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')\n",
        "            except Exception:\n",
        "                pass  # Ignore errors in conversion\n",
        "\n",
        "        return {\n",
        "            'Size': (num_rows, num_columns),\n",
        "            'Number of Rows': num_rows,\n",
        "            'Number of Columns': num_columns,\n",
        "            'Columns with No Nulls': no_null_cols,\n",
        "            'Columns with No Duplicates': no_duplicates_cols\n",
        "        }\n",
        "\n",
        "    def generate_metadata(self):\n",
        "        \"\"\"\n",
        "        Generates metadata of the DataFrame, including:\n",
        "        - Data type of each column\n",
        "        - Whether the column has null values\n",
        "        - Whether the column has duplicate values\n",
        "        \"\"\"\n",
        "        metadata = pd.DataFrame({\n",
        "            'Column': self.df.columns,\n",
        "            'Data Type': [str(self.df[col].dtype) for col in self.df.columns],\n",
        "            'Has Nulls': ['Yes' if self.df[col].isna().any() else 'No' for col in self.df.columns],\n",
        "            'Has Duplicates': ['Yes' if self.df[col].duplicated().any() else 'No' for col in self.df.columns]\n",
        "        })\n",
        "\n",
        "        return metadata\n",
        "\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = \"netflix_titles.csv\"  # Provide the correct path to your CSV or Excel file\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# Generate metadata and display it as a table\n",
        "metadata_df = df_ops.generate_metadata()\n",
        "display(metadata_df)\n",
        "\n",
        "# Generate summary data and clean it for display\n",
        "summary_data = df_ops.summarize()\n",
        "summary_data_cleaned = {\n",
        "    'Size': str(summary_data['Size']),\n",
        "    'Number of Rows': summary_data['Number of Rows'],\n",
        "    'Number of Columns': summary_data['Number of Columns'],\n",
        "    'Columns with No Nulls': ', '.join(summary_data['Columns with No Nulls']),\n",
        "    'Columns with No Duplicates': ', '.join(summary_data['Columns with No Duplicates'])\n",
        "}\n",
        "\n",
        "# Creating a DataFrame from the cleaned summary data\n",
        "summary_df = pd.DataFrame(list(summary_data_cleaned.items()), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display summary DataFrame\n",
        "display(summary_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "SB-352LtHOaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxNYC3j3tj8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def summarize(self):\n",
        "        \"\"\"\n",
        "        Summarizes the DataFrame by providing:\n",
        "        - Size of the DataFrame (rows, columns)\n",
        "        - Columns with no missing values\n",
        "        - Columns where all values are unique (no duplicates)\n",
        "        - Standardizes datetime columns to a common format\n",
        "        \"\"\"\n",
        "        # Get DataFrame shape\n",
        "        num_rows, num_columns = self.df.shape\n",
        "\n",
        "        # Identify columns with no null values\n",
        "        no_null_cols = [col for col in self.df.columns if self.df[col].isna().sum() == 0]\n",
        "\n",
        "        # Identify columns where all values are unique (no duplicates)\n",
        "        no_duplicates_cols = [col for col in self.df.columns if self.df[col].nunique() == num_rows]\n",
        "\n",
        "        # Convert datetime columns to a standardized format if possible\n",
        "        for col in self.df.select_dtypes(include=['object']).columns:\n",
        "            try:\n",
        "                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')\n",
        "            except Exception:\n",
        "                pass  # Ignore errors in conversion\n",
        "\n",
        "        return {\n",
        "            'Size': (num_rows, num_columns),\n",
        "            'Number of Rows': num_rows,\n",
        "            'Number of Columns': num_columns,\n",
        "            'Columns with No Nulls': no_null_cols,\n",
        "            'Columns with No Duplicates': no_duplicates_cols\n",
        "        }\n",
        "\n",
        "    def generate_metadata(self):\n",
        "        \"\"\"\n",
        "        Generates metadata of the DataFrame, including:\n",
        "        - Data type of each column\n",
        "        - Whether the column has null values\n",
        "        - Whether the column has duplicate values\n",
        "        \"\"\"\n",
        "        metadata = pd.DataFrame({\n",
        "            'Column': self.df.columns,\n",
        "            'Data Type': [str(self.df[col].dtype) for col in self.df.columns],\n",
        "            'Has Nulls': ['Yes' if self.df[col].isna().any() else 'No' for col in self.df.columns],\n",
        "            'Has Duplicates': ['Yes' if self.df[col].duplicated().any() else 'No' for col in self.df.columns]\n",
        "        })\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring index integrity.\n",
        "\n",
        "        :param columns_to_explode: list, columns that need to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Explode multiple columns together and reset the index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        return self.df\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = \"netflix_titles.csv\"  # Provide the correct path to your CSV or Excel file\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# List of columns to explode\n",
        "# columns_to_explode = ['cast','director']  # Change as per your dataset\n",
        "# explode_columns = df_ops.explode_columns(columns_to_explode)\n",
        "# display(explode_columns)\n",
        "# Explode columns\n",
        "df_exploded = df_ops.explode_columns(columns_to_explode)\n",
        "\n",
        "# Display exploded DataFrame\n",
        "display(df_exploded)\n",
        "\n",
        "# Generate metadata and display it as a table\n",
        "metadata_df = df_ops.generate_metadata()\n",
        "display(metadata_df)\n",
        "\n",
        "# Generate summary data and clean it for display\n",
        "summary_data = df_ops.summarize()\n",
        "summary_data_cleaned = {\n",
        "    'Size': str(summary_data['Size']),\n",
        "    'Number of Rows': summary_data['Number of Rows'],\n",
        "    'Number of Columns': summary_data['Number of Columns'],\n",
        "    'Columns with No Nulls': ', '.join(summary_data['Columns with No Nulls']),\n",
        "    'Columns with No Duplicates': ', '.join(summary_data['Columns with No Duplicates'])\n",
        "}\n",
        "\n",
        "# Creating a DataFrame from the cleaned summary data\n",
        "summary_df = pd.DataFrame(list(summary_data_cleaned.items()), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display summary DataFrame\n",
        "# display(summary_df)\n",
        "columns_to_explode = ['cast' ]  # Change as per your dataset\n",
        "explode_columns = df_ops.explode_columns(columns_to_explode)\n",
        "display(explode_columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0FSSh5qlKgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring index integrity.\n",
        "\n",
        "        :param columns_to_explode: list, columns that need to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Explode multiple columns together and reset the index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        return self.df\n",
        "columns_to_explode = ['cast' ]  # Change as per your dataset\n",
        "explode_columns = df_ops.explode_columns(columns_to_explode)\n",
        "display(explode_columns)"
      ],
      "metadata": {
        "id": "1Gw6PbjunBJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n",
        "df_exploded = df.explode(['cast']).reset_index(drop=True)\n",
        "df_exploded\n"
      ],
      "metadata": {
        "id": "y9sKNNeHqatR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring non-exploded columns remain intact.\n",
        "\n",
        "        :param columns_to_explode: list of columns to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Convert specified columns to lists if they are comma-separated strings\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df[col].apply(lambda x: x.split(', ') if isinstance(x, str) else [None])\n",
        "\n",
        "        # Explode multiple columns simultaneously and reset index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        # Forward-fill missing values to maintain alignment in non-exploded columns\n",
        "        non_exploded_cols = [col for col in self.df.columns if col not in columns_to_explode]\n",
        "        self.df[non_exploded_cols] = self.df[non_exploded_cols].ffill()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "# Replace with your actual file path\n",
        "file_path = \"\"  # Provide the correct path to your CSV or Excel file\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# List of columns to explode\n",
        "columns_to_explode = ['director', 'cast']  # Change as per your dataset\n",
        "\n",
        "# Explode columns\n",
        "df_exploded = df_ops.explode_columns(columns_to_explode)\n",
        "\n",
        "# Display exploded DataFrame\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Exploded DataFrame\", dataframe=df_exploded)\n"
      ],
      "metadata": {
        "id": "6sCiUIj7qd1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring non-exploded columns remain intact.\n",
        "\n",
        "        :param columns_to_explode: list of columns to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Convert specified columns to lists if they are comma-separated strings\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df[col].apply(lambda x: x.split(', ') if isinstance(x, str) else [None])\n",
        "\n",
        "        # Explode multiple columns simultaneously and reset index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        # Forward-fill missing values to maintain alignment in non-exploded columns\n",
        "        non_exploded_cols = [col for col in self.df.columns if col not in columns_to_explode]\n",
        "        self.df[non_exploded_cols] = self.df[non_exploded_cols].ffill()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "# Use the given CSV file\n",
        "file_path = \"netflix_titles.csv\"\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# List of columns to explode\n",
        "columns_to_explode = ['director', 'cast']  # Adjust as needed\n",
        "\n",
        "# Explode columns\n",
        "df_exploded = df_ops.explode_columns(columns_to_explode)\n",
        "\n",
        "# Return the new DataFrame with exploded data and other columns intact\n",
        "df_exploded.head()  # Displaying only the first few rows for verification\n"
      ],
      "metadata": {
        "id": "CANP18sxst5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring non-exploded columns remain intact.\n",
        "\n",
        "        :param columns_to_explode: list of columns to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Convert specified columns to lists if they are comma-separated strings\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df[col].apply(lambda x: x.split(', ') if isinstance(x, str) else [None])\n",
        "\n",
        "        # Ensure all lists have the same length by padding with None\n",
        "        max_length = self.df[columns_to_explode].applymap(len).max(axis=1)  # Find max length per row\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df[col].apply(lambda x: x + [None] * (max_length.loc[x.name] - len(x)))\n",
        "\n",
        "        # Explode multiple columns together and reset index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        # Forward-fill missing values to maintain alignment in non-exploded columns\n",
        "        non_exploded_cols = [col for col in self.df.columns if col not in columns_to_explode]\n",
        "        self.df[non_exploded_cols] = self.df[non_exploded_cols].ffill()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "# Use the given CSV file\n",
        "file_path = \"netflix_titles.csv\"\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# List of columns to explode\n",
        "columns_to_explode = ['director', 'cast']  # Adjust as needed\n",
        "\n",
        "# Explode columns safely\n",
        "df_exploded = df_ops.explode_columns(columns_to_explode)\n",
        "\n",
        "# Return the new DataFrame with exploded data and other columns intact\n",
        "df_exploded.head()  # Displaying only the first few rows for verification\n"
      ],
      "metadata": {
        "id": "Mdw7WLDctDIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataFrameOps:\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the class with a CSV or Excel file and creates a DataFrame.\n",
        "\n",
        "        :param file_path: str, file path to the CSV or Excel file.\n",
        "        \"\"\"\n",
        "        if file_path.endswith('.csv'):\n",
        "            self.df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith('.xlsx'):\n",
        "            self.df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"File must be either a CSV or Excel file.\")\n",
        "\n",
        "    def explode_columns(self, columns_to_explode):\n",
        "        \"\"\"\n",
        "        Explodes the specified list of columns while ensuring non-exploded columns remain intact.\n",
        "\n",
        "        :param columns_to_explode: list of columns to be exploded.\n",
        "        :return: DataFrame with exploded columns.\n",
        "        \"\"\"\n",
        "        if not all(col in self.df.columns for col in columns_to_explode):\n",
        "            raise ValueError(\"One or more specified columns are not present in the DataFrame.\")\n",
        "\n",
        "        # Convert specified columns to lists if they are comma-separated strings\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df[col].apply(lambda x: x.split(', ') if isinstance(x, str) else [None])\n",
        "\n",
        "        # Ensure all lists have the same length by padding with None\n",
        "        max_length = self.df[columns_to_explode].map(len).max(axis=1)  # Find max length per row\n",
        "        for col in columns_to_explode:\n",
        "            self.df[col] = self.df.apply(lambda row: row[col] + [None] * (max_length[row.name] - len(row[col])), axis=1)\n",
        "\n",
        "        # Explode multiple columns together and reset index\n",
        "        self.df = self.df.explode(columns_to_explode).reset_index(drop=True)\n",
        "\n",
        "        # Forward-fill missing values to maintain alignment in non-exploded columns\n",
        "        non_exploded_cols = [col for col in self.df.columns if col not in columns_to_explode]\n",
        "        self.df[non_exploded_cols] = self.df[non_exploded_cols].ffill()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "# Use the given CSV file\n",
        "file_path = \"netflix_titles.csv\"\n",
        "\n",
        "# Instantiate the class\n",
        "df_ops = DataFrameOps(file_path)\n",
        "\n",
        "# List of columns to explode\n",
        "columns_to_explode = ['director', 'cast', 'country', 'listed_in']  # Adjust as needed\n",
        "\n",
        "# Explode columns safely\n",
        "df_exploded = df_ops.explode_columns(columns_to_explode)\n",
        "\n",
        "# Return the new DataFrame with exploded data and other columns intact\n",
        "df_exploded.head()  # Displaying only the first few rows for verification\n"
      ],
      "metadata": {
        "id": "v65_8TQRtUXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['title'] == 'Blood & Water']"
      ],
      "metadata": {
        "id": "Fdf85vfft7Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_exploded.info()\n",
        "df_exploded.size\n",
        "\n"
      ],
      "metadata": {
        "id": "E54WEwTKuXfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_act_dir = df_exploded.set_index('show_id')[['director', 'cast']]\n",
        "df_act_dir = df_exploded.set_index('show_id')[['director', 'cast']].nunique()\n",
        "df_act_dir\n"
      ],
      "metadata": {
        "id": "xTwVZ7T2xp_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate entries based on 'show_id' to ensure unique shows\n",
        "df_unique = df_exploded.drop_duplicates(subset=['show_id'])\n",
        "\n",
        "# Create a subset DataFrame with show_id as the index, containing director and cast\n",
        "df_act_dir = df_unique.set_index('show_id')[['director', 'cast', 'title']]\n",
        "\n",
        "# Drop rows where either director or cast is NaN\n",
        "df_act_dir = df_act_dir.dropna()\n",
        "\n",
        "# Count occurrences of each (director, actor) pair\n",
        "pair_counts = df_act_dir.groupby(['director', 'cast']).size().reset_index(name='Number of Shows')\n",
        "\n",
        "# Get the most frequent director-actor pair\n",
        "top_pair = pair_counts.sort_values(by='Number of Shows', ascending=False).head(5)\n",
        "\n",
        "# Display the results\n",
        "top_pair\n"
      ],
      "metadata": {
        "id": "CUn-ed0lxq0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subset DataFrame with show_id as the index, containing director, cast, and title\n",
        "df_act_dir = df_unique.set_index('show_id')[['director', 'cast', 'title']]\n",
        "\n",
        "# Drop rows where either director or cast is NaN\n",
        "df_act_dir = df_act_dir.dropna()\n",
        "\n",
        "# Count occurrences of each (director, actor) pair and include titles\n",
        "pair_counts = df_act_dir.groupby(['director', 'cast']).agg({\n",
        "    'title': lambda x: list(x),  # Collect titles as a list\n",
        "    'title': 'count'  # Count number of shows\n",
        "}).reset_index().rename(columns={'title': 'Number of Shows'})\n",
        "\n",
        "# Get the top 5 most frequent director-actor pairs\n",
        "top_pairs = pair_counts.sort_values(by='Number of Shows', ascending=False).head(5)\n",
        "\n",
        "# Merge with original dataset to include the list of titles\n",
        "top_pairs_with_titles = df_act_dir.groupby(['director', 'cast'])['title'].agg(list).reset_index()\n",
        "\n",
        "# Merge the counts with the titles\n",
        "final_top_pairs = top_pairs.merge(top_pairs_with_titles, on=['director', 'cast'], how='left')\n",
        "\n",
        "# Display the results\n",
        "final_top_pairs\n"
      ],
      "metadata": {
        "id": "8jTK1dMmz3Oa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}